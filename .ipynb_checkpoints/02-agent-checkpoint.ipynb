{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5e60873b-8ba4-4b14-a9a6-23e57cd3f781",
   "metadata": {},
   "outputs": [],
   "source": [
    "import autogen\n",
    "from autogen import config_list_from_json "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "99edeeed-635a-4e0b-86bd-8ad6fcb8df4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_list = config_list_from_json(env_or_file=\"OAI_CONFIG_LIST\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "18ff60ae-d346-49b5-b6a5-dc01f8a41c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_config = dict(config_list=config_list,\n",
    "                  timeout=120,\n",
    "                  temperature=0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "067aa1d0-00c2-451e-a8be-10344821cf93",
   "metadata": {},
   "source": [
    "## Tech Team Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a4c1a27d-ca0e-4b7e-9d2b-9175cfab4082",
   "metadata": {},
   "outputs": [],
   "source": [
    "priming = 'Think step by step'\n",
    "\n",
    "user_proxy = autogen.UserProxyAgent(\n",
    "    name='CEO',\n",
    "    system_message=\"CEO. Interacts with Product Manager to discuss product requirements. Plan execution needs to be approved by CEO.\" + priming,\n",
    "    code_execution_config=False,\n",
    ")\n",
    "\n",
    "product_manager = autogen.AssistantAgent(\n",
    "    name='Senior Product Manager',\n",
    "    system_message='You are a Senior Product Manager. You have vast knowledge about product development. You understand product requirements and are able to write excellent requirement documentation. When writing requirement documentation, you start with the value proposition, then user stories for the list of features, and then the acceptance criteria as well as the definition of done. You will also delegate additional research task to the UI/UX researcher. Always asks the CEO for approval after you have an initial draft. If the draft is rejected, you will iterate over them by asking questions to the UI/UX Researcher. Once it is approved, discuss with the Engineer on the technical implementation. Always check with them if the requirements makes sense and it can be achieved technically. Once the engineer has come up with the solution, discuss with the Data Engineer on what are the useful metrics to track, and why.' + priming,\n",
    "    llm_config=llm_config,\n",
    "    code_execution_config=False\n",
    ")\n",
    "\n",
    "ui_ux_researcher = autogen.AssistantAgent(\n",
    "    name='Senior UI/UX Researcher',\n",
    "    system_message='You are a Senior UI/UX Researcher. You emphatize with the users and understands how to create the best experience for users. You know how to conduct proper user research and are able to communicate the challenges to the Product Manager. When discussing with the Product Manager, be critical with your thoughts and clarify the requirements. Do not agree all the time with the Product Manager if the requirement does not make sense.' + priming,\n",
    "    llm_config=llm_config,\n",
    "    code_execution_config=False\n",
    ")\n",
    "\n",
    "\n",
    "engineer = autogen.AssistantAgent(\n",
    "    name=\"10x Engineer\",\n",
    "    system_message='You are a 10x enginer. You have vast experienced in Software Development, and are able to design the best solution given the tradeoffs. When given a requirement, do not jump straight into the code. Clarify the requirements first. Then start with an initial architecture and document the process. You write your documentation in Markdown. Once you are clear on the requirements, write just enough code and ask the executor to run it. Always verify that the code works.' + priming,\n",
    "    llm_config=llm_config,\n",
    "    code_execution_config=False\n",
    ")\n",
    "\n",
    "executor = autogen.UserProxyAgent(\n",
    "    name=\"Executor\",\n",
    "    system_message=\"Executor. Execute the code written by the engineer and report the result.\",\n",
    "    human_input_mode=\"NEVER\",\n",
    "    llm_config=llm_config,\n",
    "    code_execution_config={\"last_n_messages\": 3, \"work_dir\": \"code\"},\n",
    ")\n",
    "\n",
    "\n",
    "data_analyst = autogen.AssistantAgent(\n",
    "    name=\"Senior Data Analyst\",\n",
    "    llm_config=llm_config,\n",
    "    system_message='You are a Senior Data Analyst. You have vast amount of knowledge on product metrics and what adds value to the business. When approached by the Product Manager, always check what features are available, then suggests the metrics that will add value to the business.' + priming,\n",
    ")\n",
    "\n",
    "\n",
    "groupchat = autogen.GroupChat(agents=[user_proxy, product_manager, engineer, data_analyst, executor, ui_ux_researcher], messages=[], max_round=50)\n",
    "manager = autogen.GroupChatManager(groupchat=groupchat, llm_config=llm_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c228b382-54fd-4682-934c-c95d53d87981",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CEO (to chat_manager):\n",
      "\n",
      "we want to be visionary in the recruitment industry\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Provide feedback to chat_manager. Press enter to skip and use auto-reply, or type 'exit' to end the conversation:  suggest some features that differentiates us from our competitor\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CEO (to chat_manager):\n",
      "\n",
      "suggest some features that differentiates us from our competitor\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Senior Product Manager (to chat_manager):\n",
      "\n",
      "1. **Applicant tracking system (ATS) that is integrated with social media and other sources of talent.** This will allow us to reach a wider pool of candidates and identify the best-fit candidates for our clients.\n",
      "2. **A predictive analytics engine that can help us identify candidates who are more likely to be successful in a given role.** This will allow us to make more informed hiring decisions and reduce the risk of hiring the wrong person.\n",
      "3. **A robust onboarding process that helps new hires get up to speed quickly and effectively.** This will ensure that our new hires are productive members of the team from day one.\n",
      "4. **A comprehensive employee development program that helps our employees grow and progress in their careers.** This will ensure that we have a talented and engaged workforce that is capable of meeting the challenges of the future.\n",
      "5. **A strong focus on customer service that ensures that our clients are satisfied with our services.** This will help us build long-term relationships with our clients and ensure that they continue to use our services in the future.\n",
      "\n",
      "These are just a few of the features that could help us to be visionary in the recruitment industry. By implementing these features, we can differentiate ourselves from our competitors and provide our clients with the best possible service.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Senior Product Manager (to chat_manager):\n",
      "\n",
      "1. **Applicant tracking system (ATS) that is integrated with social media and other sources of talent.**\n",
      "\n",
      "* **Benefits:**\n",
      "    * Reach a wider pool of candidates\n",
      "    * Identify the best-fit candidates for our clients\n",
      "* **Challenges:**\n",
      "    * Cost of implementation\n",
      "    * Maintaining the system\n",
      "    * Ensuring that the system is user-friendly\n",
      "\n",
      "2. **A predictive analytics engine that can help us identify candidates who are more likely to be successful in a given role.**\n",
      "\n",
      "* **Benefits:**\n",
      "    * Make more informed hiring decisions\n",
      "    * Reduce the risk of hiring the wrong person\n",
      "* **Challenges:**\n",
      "    * Cost of implementation\n",
      "    * Maintaining the system\n",
      "    * Ensuring that the system is accurate\n",
      "\n",
      "3. **A robust onboarding process that helps new hires get up to speed quickly and effectively.**\n",
      "\n",
      "* **Benefits:**\n",
      "    * Ensure that our new hires are productive members of the team from day one\n",
      "    * Reduce the time it takes for new hires to become productive\n",
      "* **Challenges:**\n",
      "    * Developing and implementing an effective onboarding process\n",
      "    * Ensuring that the onboarding process is aligned with the company's culture\n",
      "\n",
      "4. **A comprehensive employee development program that helps our employees grow and progress in their careers.**\n",
      "\n",
      "* **Benefits:**\n",
      "    * Ensure that we have a talented and engaged workforce\n",
      "    * Capable of meeting the challenges of the future\n",
      "* **Challenges:**\n",
      "    * Developing and implementing an effective employee development program\n",
      "    * Ensuring that the program is aligned with the company's goals\n",
      "\n",
      "5. **A strong focus on customer service that ensures that our clients are satisfied with our services.**\n",
      "\n",
      "* **Benefits:**\n",
      "    * Build long-term relationships with our clients\n",
      "    * Ensure that they continue to use our services in the future\n",
      "* **Challenges:**\n",
      "    * Providing excellent customer service can be time-consuming\n",
      "    * Ensuring that all customer interactions are handled in a timely and professional manner\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "[autogen.oai.completion: 11-24 00:21:27] {238} INFO - retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/alextanhongpin/Library/Caches/pypoetry/virtualenvs/python-autogen-Wc7M55GE-py3.11/lib/python3.11/site-packages/openai/api_requestor.py\", line 413, in handle_error_response\n",
      "    error_data = resp[\"error\"]\n",
      "                 ~~~~^^^^^^^^^\n",
      "KeyError: 'error'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/alextanhongpin/Library/Caches/pypoetry/virtualenvs/python-autogen-Wc7M55GE-py3.11/lib/python3.11/site-packages/autogen/oai/completion.py\", line 224, in _get_response\n",
      "    response = openai_completion.create(request_timeout=request_timeout, **config)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/alextanhongpin/Library/Caches/pypoetry/virtualenvs/python-autogen-Wc7M55GE-py3.11/lib/python3.11/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/alextanhongpin/Library/Caches/pypoetry/virtualenvs/python-autogen-Wc7M55GE-py3.11/lib/python3.11/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 155, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "                           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/alextanhongpin/Library/Caches/pypoetry/virtualenvs/python-autogen-Wc7M55GE-py3.11/lib/python3.11/site-packages/openai/api_requestor.py\", line 299, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/alextanhongpin/Library/Caches/pypoetry/virtualenvs/python-autogen-Wc7M55GE-py3.11/lib/python3.11/site-packages/openai/api_requestor.py\", line 710, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/Users/alextanhongpin/Library/Caches/pypoetry/virtualenvs/python-autogen-Wc7M55GE-py3.11/lib/python3.11/site-packages/openai/api_requestor.py\", line 775, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/alextanhongpin/Library/Caches/pypoetry/virtualenvs/python-autogen-Wc7M55GE-py3.11/lib/python3.11/site-packages/openai/api_requestor.py\", line 415, in handle_error_response\n",
      "    raise error.APIError(\n",
      "openai.error.APIError: Invalid response object from API: '{\"detail\":\"PalmException - No response received. Original response - Completion(candidates=[],\\\\n           result=None,\\\\n           filters=[{\\'reason\\': <BlockedReason.OTHER: 2>}],\\\\n           safety_feedback=[])\\\\n\\\\nTraceback (most recent call last):\\\\n  File \\\\\"/Users/alextanhongpin/Documents/python/python-litellm/.venv/lib/python3.11/site-packages/litellm/llms/palm.py\\\\\", line 153, in completion\\\\n    completion_response = model_response[\\\\\"choices\\\\\"][0][\\\\\"message\\\\\"].get(\\\\\"content\\\\\")\\\\n                          ~~~~~~~~~~~~~~~~~~~~~~~~~^^^\\\\nIndexError: list index out of range\\\\n\\\\nDuring handling of the above exception, another exception occurred:\\\\n\\\\nTraceback (most recent call last):\\\\n  File \\\\\"/Users/alextanhongpin/Documents/python/python-litellm/.venv/lib/python3.11/site-packages/litellm/main.py\\\\\", line 1039, in completion\\\\n    model_response = palm.completion(\\\\n                     ^^^^^^^^^^^^^^^^\\\\n  File \\\\\"/Users/alextanhongpin/Documents/python/python-litellm/.venv/lib/python3.11/site-packages/litellm/llms/palm.py\\\\\", line 155, in completion\\\\n    raise PalmError(status_code=400, message=f\\\\\"No response received. Original response - {response}\\\\\")\\\\nlitellm.llms.palm.PalmError: No response received. Original response - Completion(candidates=[],\\\\n           result=None,\\\\n           filters=[{\\'reason\\': <BlockedReason.OTHER: 2>}],\\\\n           safety_feedback=[])\\\\n\\\\nDuring handling of the above exception, another exception occurred:\\\\n\\\\nTraceback (most recent call last):\\\\n  File \\\\\"/Users/alextanhongpin/Documents/python/python-litellm/.venv/lib/python3.11/site-packages/litellm/proxy/proxy_server.py\\\\\", line 663, in chat_completion\\\\n    return litellm_completion(\\\\n           ^^^^^^^^^^^^^^^^^^^\\\\n  File \\\\\"/Users/alextanhongpin/Documents/python/python-litellm/.venv/lib/python3.11/site-packages/litellm/proxy/proxy_server.py\\\\\", line 553, in litellm_completion\\\\n    raise e\\\\n  File \\\\\"/Users/alextanhongpin/Documents/python/python-litellm/.venv/lib/python3.11/site-packages/litellm/proxy/proxy_server.py\\\\\", line 549, in litellm_completion\\\\n    response = litellm.completion(*args, **kwargs)\\\\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\\\n  File \\\\\"/Users/alextanhongpin/Documents/python/python-litellm/.venv/lib/python3.11/site-packages/litellm/utils.py\\\\\", line 1261, in wrapper\\\\n    raise e\\\\n  File \\\\\"/Users/alextanhongpin/Documents/python/python-litellm/.venv/lib/python3.11/site-packages/litellm/utils.py\\\\\", line 1195, in wrapper\\\\n    result = original_function(*args, **kwargs)\\\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\\\n  File \\\\\"/Users/alextanhongpin/Documents/python/python-litellm/.venv/lib/python3.11/site-packages/litellm/main.py\\\\\", line 1383, in completion\\\\n    raise exception_type(\\\\n          ^^^^^^^^^^^^^^^\\\\n  File \\\\\"/Users/alextanhongpin/Documents/python/python-litellm/.venv/lib/python3.11/site-packages/litellm/utils.py\\\\\", line 4275, in exception_type\\\\n    raise e\\\\n  File \\\\\"/Users/alextanhongpin/Documents/python/python-litellm/.venv/lib/python3.11/site-packages/litellm/utils.py\\\\\", line 3715, in exception_type\\\\n    raise BadRequestError(\\\\nlitellm.exceptions.BadRequestError: PalmException - No response received. Original response - Completion(candidates=[],\\\\n           result=None,\\\\n           filters=[{\\'reason\\': <BlockedReason.OTHER: 2>}],\\\\n           safety_feedback=[])\\\\n\"}' (HTTP response code was 400)\n"
     ]
    }
   ],
   "source": [
    "user_proxy.initiate_chat(\n",
    "    manager,\n",
    "    message=\"we want to be visionary in the recruitment industry\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4fd7e5c-2e12-4c28-a3fb-3703fa75bef9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
